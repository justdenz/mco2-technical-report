{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Project - Adding category feature.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justdenz/mco2-technical-report/blob/main/Data_Project_Adding_category_feature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm4vGS4tE4pv"
      },
      "source": [
        "This notebook adds the commit types category of all commit messages from the [Github Dataset](https://www.kaggle.com/dhruvildave/github-commit-messages-dataset)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYLDKK4xr9Y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "149b5505-2ac6-49e6-c3a1-e7e3d6ab7213"
      },
      "source": [
        "!pip install gdown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIH2D9C4kF_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aaf494c-8016-4b34-f866-f1859bd6dfe6"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1YuyNK-idGHj1-ltmGkRtok7ml7pP6c6E\n",
        "!unzip github.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YuyNK-idGHj1-ltmGkRtok7ml7pP6c6E\n",
            "To: /content/github.zip\n",
            "946MB [00:07, 119MB/s]\n",
            "Archive:  github.zip\n",
            "  inflating: full.csv                \n",
            "  inflating: oneline.csv             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b35Jc1dIESMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fac236f-a4f9-4396-a957-74538bc981ed"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "from datetime import datetime as dt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.graphics as smg\n",
        "import statsmodels.stats as sm_stats\n",
        "import statsmodels.tsa.api as tsa\n",
        "\n",
        "from scipy import stats\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGupV4w6tZ01"
      },
      "source": [
        "df = pd.read_csv('full.csv', parse_dates=True, infer_datetime_format=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q-Eods9jVpE"
      },
      "source": [
        "import re\n",
        "from typing import List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmF9-ZKvFZrd"
      },
      "source": [
        "Adding the categories features an intricute regex matching using keywords. These functions attempt to match the category as either:\n",
        "\n",
        "*   Fix\n",
        "*   Core Bug\n",
        "*   Refactor\n",
        "*   Security\n",
        "*   Others\n",
        "\n",
        "The \"other\" categories included addition of new features, or general improvent.\n",
        "\n",
        "This process is mainly adapted from this [example](https://www.kaggle.com/amarabuco/commits-eda).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPlo5MXmSsNJ"
      },
      "source": [
        "Language Util - This is the base regex reading methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcpe4mBaStqo"
      },
      "source": [
        "regex_list : List[str]\n",
        "\n",
        "SCHEMA_NAME = 'general'\n",
        "file_scheme = '([a-zA-Z0-9_\\*\\.])+\\.[a-zA-Z]{1,4}'\n",
        "\n",
        "REGULAR_SUFFIX = '(?:s|ed|ing)?'\n",
        "VERB_E_SUFFIX = '(?:e|es|ed|ing)'\n",
        "\n",
        "NEAR_ENOUGH = '[\\S\\s]{0,40}'\n",
        "\n",
        "#term_seperator = \"(\\s|\\.|\\?|\\!|\\[|\\]|\\(|\\)|\\:|^|$|\\,|\\'|\\\"|/|#|\\$|\\%|&|\\*|\\+|=|`|;|<|>|@|~|{|}|-|\\|)\" # Adding - should be tuned\n",
        "#term_seperator = \"(\\s|\\.|\\?|\\!|\\[|\\]|\\(|\\)|\\:|^|$|\\,|\\'|\\\"|/|#|\\$|\\%|&|\\*|\\+|=|`|;|<|>|@|~|{|}|\\|)\"\n",
        "#term_seperator = \"[^abcdefghijklmnopqrstuvwxyz]\"\n",
        "term_seperator = \"(\\s|\\.|\\?|\\!|\\[|\\]|\\(|\\)|\\:|^|$|\\,|\\'|\\\"|/|#|\\$|\\%|&|\\*|\\+|=|`|;|<|>|@|~|{|}|_|\\|)\"\n",
        "#term_seperator = \"(\\s|\\.|\\?|\\!|\\[|\\]|\\(|\\)|\\:|^|$|\\,|/|#|\\$|\\%|&|\\*|\\+|=|`|;|<|>|@|~|{|}|_|\\|)\" # no \",'\n",
        "#term_seperator = \"(\\s|\\.|\\?|\\!|\\[|\\]|\\(|\\)|\\:|^|$|\\,|\\'|\\\"|#|\\$|\\%|&|\\*|\\+|=|`|;|<|>|@|~|{|}|_|\\|)\" # without /\n",
        "\n",
        "# Negation\n",
        "negation_terms = [\"aren't\",\n",
        " 'arent',\n",
        " \"can't\",\n",
        " 'cannot',\n",
        " 'cant',\n",
        " 'could not',\n",
        " \"couldn't\",\n",
        " 'couldnt',\n",
        " \"didn't\",\n",
        " 'didnt',\n",
        " \"doesn't\",\n",
        " 'doesnt',\n",
        " \"don't\",\n",
        " 'dont',\n",
        " \"hasn't\",\n",
        " \"haven't\",\n",
        " \"isn't\",\n",
        " 'isnt',\n",
        " 'lack',\n",
        " \"n't\",\n",
        " 'never',\n",
        " 'no',\n",
        " 'nobody',\n",
        " 'none',\n",
        " 'not',\n",
        " 'nothing',\n",
        " \"shouldn't\",\n",
        " 'shouldnt',\n",
        " \"weren't\",\n",
        " 'werent',\n",
        " 'without',\n",
        " \"won't\",\n",
        " 'wont',\n",
        " \"wouldn't\",\n",
        " 'wouldnt']\n",
        "\n",
        "# TODO - consider adding if, maybe\n",
        "modals = [#'if', 'maybe',\n",
        "          'can', 'could', 'ha(?:ve|s|d)', 'may', 'might', 'must', 'need', 'ought', 'shall'\n",
        "    , 'should', 'will', 'would']\n",
        "\n",
        "\n",
        "\n",
        "# TODO - check https://arxiv.org/pdf/2001.09148.pdf for more\n",
        "\n",
        "security_terms = [\n",
        " 'advisory',\n",
        " 'attack',\n",
        " 'authenticat(e|ion)',\n",
        " 'brute force', # consider\n",
        " 'bug bount(y|ies)',\n",
        " 'bypass', # consider\n",
        " 'constant time',\n",
        " 'crack',\n",
        " 'credential(s)?',\n",
        " 'cross-origin',\n",
        " 'cross site',\n",
        " 'cve(-d+)?(-d+)?',\n",
        " 'clickjack',\n",
        " 'cyber',\n",
        " 'denial of service',\n",
        " '(de)?serializ', # consider\n",
        " 'directory traversal',\n",
        " 'dos', # consider\n",
        " 'exploit',\n",
        " 'expos(e|ing)',\n",
        " 'hack',\n",
        " 'hijack',\n",
        " 'harden',\n",
        " #'infinite loop', # consider\n",
        " 'injection',\n",
        " '(in)?secur(e|ity)',\n",
        " 'lockout',\n",
        " 'malicious',\n",
        " 'malware',\n",
        " 'nvd' # NVD\n",
        " 'open redirect',\n",
        " 'osvdb', # OSVDB\n",
        " 'overflow', # consider\n",
        " 'password(s)?',\n",
        " 'permission(s)?',\n",
        " 'poison',\n",
        " 'port scan',\n",
        " 'privilege',\n",
        " # 'proof of concept', # consider\n",
        " 'rce', # remote code execution\n",
        " 'redos' # ReDoS\n",
        " 'remote code execution',\n",
        " 'return oriented programming',\n",
        " 'security',\n",
        " 'session fixation',\n",
        " 'spoof',\n",
        " 'threat',\n",
        " 'timing', # consider\n",
        " 'traversal',\n",
        " 'unauthori[z|s]ed',\n",
        " 'vulnerabilit(?:y|ies)',\n",
        " 'x(?: |-)frame(?: |-)options',\n",
        " 'xss',\n",
        " 'xsrf', # XSRF\n",
        " 'xxe' # XXE\n",
        "    ]\n",
        "\n",
        "\n",
        "documentation_entities = [\n",
        "    'change(?:s)?(?: |-)?(list|log|set|file)',\n",
        "    'comment(s)?',\n",
        "    'copy(?: |-)?right(?:s)?',\n",
        "    'doc(?:s)?',\n",
        "    'documentation',\n",
        "    'explanation(?:s)?',\n",
        "    'man(?: |-)?page(?:s)?',\n",
        "    'manual',\n",
        "    'note(?:s)?',\n",
        "    'readme(?:.md)?',\n",
        "    r'[-a-z\\d_/\\\\]*.(md|txt)',\n",
        "    'translation(?:s)?',\n",
        "    'java(?: |-)?doc(?:s)?',\n",
        "    'java(?: |-)?documentation',\n",
        "    'example(?:s)?',\n",
        "    'diagram(?:s)?',\n",
        "    'guide(?:s)?',\n",
        "    'gitignore',\n",
        "    'icon(?:s)?',\n",
        "    'doc(?: |-)?string(?:s)?',\n",
        "    'tutorials(?:s)?',\n",
        "    'help',\n",
        "    'man',\n",
        "    'doc(?: |-)?string(?:s)?',\n",
        "    'desc(?:ription)?(?:s)?',\n",
        "    'copy(?: |-)?right(?:s)?',\n",
        "    'explanation(?:s)?',\n",
        "    'release notes',\n",
        "    'tag(?:s)?', # Git commit tags\n",
        "\n",
        "]\n",
        "\n",
        "prefective_entities = documentation_entities +[\n",
        "    'indentation(?:s)?'\n",
        "    , 'style'\n",
        "    , 'todo(s)?'\n",
        "    , 'typo(s)?'\n",
        "    , 'verbosity']\n",
        "\n",
        "software_goals = ['abstraction', 'coherence', 'cohesion', 'complexity', 'correctness', 'coupling', 'dependability'\n",
        "    , 'duplication', 'efficiency', 'extensibility', 'flexibility' ,'maintainability', 'naming', 'performance', 'portability', 'quality'\n",
        "    , 'readability', 'reliability', 're(?:-| )?use' ,'re(?:-| )?usability', 'security', 'simplicity', 'testability', 'testable', 're(?:-| )?usable'\n",
        "    , 'readable', 'portable', 'maintainable', 'flexible', 'efficient', 'encapsulation'\n",
        "                  ]\n",
        "\n",
        "software_goals_modification = [\n",
        "    'better','improv(?:e|es|ed|ing)', 'increas(?:e|es|ed|ing)', 'reduc(?:e|es|ed|ing)', 'worse', 'make', 'more', 'less'\n",
        "]\n",
        "\n",
        "software_entities = ['algorithm(?:s)?',\n",
        " 'class(?:es)?',\n",
        " 'collection(?:s)?',\n",
        " 'constant(?:s)?',\n",
        " 'constructor(?:s)?',\n",
        " 'field(?:s)?',\n",
        " 'function(?:s)?',\n",
        " 'interface(?:s)?',\n",
        " 'member(?:s)?',\n",
        " 'method(?:s)?',\n",
        " 'module(?:s)?',\n",
        " 'parameter(?:s)?',\n",
        " 'procedure(?:s)?',\n",
        " 'routine(?:s)?`',\n",
        " 'structure(?:s)?',\n",
        " 'template(?:s)?',\n",
        " 'type(?:s)?',\n",
        " 'unit(?:s)?',\n",
        "]\n",
        "\n",
        "software_terms = [ 'assertion(?:s)?', 'assignment(?:s)?',  'code',  'conditional(?:s)?',  'control', 'definition(?:s)?'\n",
        "    , 'delegate', 'delegation'\n",
        "    , 'design pattern(?:s)?', 'error(?:-| )?code(?:s)?', 'exception(?:s)?',  'flag(?:s)?',  'getter(?:s)?'\n",
        "    , 'guard clause(?:s)?', 'hierarch(?:y|ies)', 'implementation(?:s)?', 'inheritance', 'inline'\n",
        "    ,  'internal', 'macro(?:s)?'\n",
        "    , 'magic number(?:s)?', 'modifier(?:s)?', 'null object(?:s)?', 'object(?:s)?'\n",
        "    , 'patch(?:es)?',  'pointer(?:s)?', 'polymorphism', 'quer(?:y|ies)',  'reference(?:s)?'\n",
        "    , 'ref(?:s)?'\n",
        "    , 'return type', 'setter(?:s)?', 'static',  'sub(?:-| )?class(?:es)?', 'super(?:-| )?class(?:es)?'\n",
        "    , '(?:sub)?(?:-| )?system(?:s)?'\n",
        "    , 'uninline'\n",
        "    #, 'value(?:s)?'\n",
        "    , 'variable(?:s)?', 'handler', 'plugin'\n",
        "    #, '(?:in)?validation'\n",
        "    #, 'input', 'output'\n",
        "    , 'contravariant', 'covariant'\n",
        "                  # , 'link(?:s)?'\n",
        "    ,\n",
        "                  'action(?:s)?'\n",
        "                  # , 'event(?:s)?'\n",
        "    , 'queue(?:s)?', 'stack(?:s)?'\n",
        "    #, 'change(?:\\s)?log'\n",
        "    , 'driver(?:s)?'\n",
        "    #, 'hook(?:s)?'\n",
        "    #, 'target(?:s)?'\n",
        "    , 'storage', 'tool(?:s)?',  'log(?:s)?', 'setting(?:s)?'\n",
        "    #, '(?:index|indexes|indices)'\n",
        "    , 'fall(?: |-)back(?:s)?', 'memory', 'param(?:s)?', 'volatile', 'file(?:s)?'\n",
        "    , 'generic(?:s)?'\n",
        "    #, 'test(?:s)?'\n",
        "    , 'initialization(?:s)?', 'public', 'protected', 'private' ,'framework', 'singelton', 'declaration(?:s)?'\n",
        "    , 'init' , 'destructor(?:s)?', 'instances(?:s)?', 'primitive(?:s)?'\n",
        "    #, 'middle man'\n",
        "    #, 'hierarchy'\n",
        "                  ] + software_entities\n",
        "\n",
        "\n",
        "# Well, we need them...\n",
        "unnedded_terms = ['unnecessary', 'unneeded', 'unused', '(?:not|never|no longer) used'\n",
        "    #, 'old'\n",
        "    , 'no longer needed', 'redundant', 'useless', 'duplicate(?:d)?', 'deprecated', 'obsolete(?:d)?', 'commented']\n",
        "\n",
        "\n",
        "static_analyzers = ['lint', 'pylint', 'tslint', 'jlint', 'jslint', 'eslint', 'klint', 'xlint', 'linter']\n",
        "\n",
        "code_review_fixes = ['(cr|pr)(s)?(-)?(d+)?\\sfix(es)?', 'fix(?:ing|es|ed)?\\s(cr|pr|code review|code-review|review)']\n",
        "\n",
        "no_message = ['no message', 'wip', 'work in progress', 'message', 'change(?:-|\\s)?set', 'commit']\n",
        "\n",
        "programming_languges = [i.lower() for i in ['Python', 'JavaScript', 'Java', 'C\\+\\+', 'PHP', 'TypeScript', 'C',\n",
        "       'C\\#', 'Go', 'Ruby', 'HTML', 'Shell', 'CSS', 'Kotlin', 'Scala',\n",
        "       'Swift', 'Jupyter Notebook', 'Rust', 'Perl', 'Lua', 'Haskell', 'R',\n",
        "       'Objective\\-C', 'Groovy', 'Vue', 'PowerShell', 'TSQL', 'Dart',\n",
        "       'Clojure', 'MATLAB', 'Emacs Lisp', 'OCaml', 'Erlang', 'Elixir',\n",
        "       'CoffeeScript', 'TeX', 'Fortran', 'Assembly', 'Vim script',\n",
        "       'PLpgSQL', 'Makefile', 'Julia', 'BitBake', 'F\\#', 'Common Lisp',\n",
        "       'Vala', 'Coq', 'Smalltalk', 'Scheme', 'Visual Basic .NET',\n",
        "       'Puppet', 'HCL', 'Smarty', 'Dockerfile', 'XSLT', 'GLSL', 'Haxe',\n",
        "       'Cuda', 'Ada', 'SQF', 'Pascal', 'PLSQL', 'Gherkin', 'Jsonnet',\n",
        "       'Nix', 'Roff', 'Apex', 'QML', 'CMake', 'D', 'Perl 6',\n",
        "       'Visual Basic', 'Objective\\-C\\+\\+', 'Prolog', 'Mathematica',\n",
        "       'Batchfile', 'Reason', 'Markdown', 'DM', 'Elm', 'FreeMarker',\n",
        "       'ABAP', 'M4', 'SystemVerilog', 'AutoHotkey', 'Verilog', 'IDL',\n",
        "       'Tcl', 'Rich Text Format', 'SaltStack', 'UnrealScript', 'Zig',\n",
        "       'WebAssembly', 'RAML', 'F\\*', 'Stan', 'ColdFusion', 'Factor',\n",
        "       'LLVM', 'Pike', 'VBA', 'Isabelle', 'OpenSCAD', 'ASP', 'Arc',\n",
        "       'Racket', 'LookML', 'SMT', 'q', 'Xojo', 'ZenScript', 'Ceylon',\n",
        "       'Agda', 'Limbo', 'SuperCollider', 'Pawn', 'xBase', 'JSON', 'Nim',\n",
        "       'M', 'XC', 'SourcePawn', 'GDScript', 'LilyPond', 'SQLPL',\n",
        "       'PostScript', \"Ren'Py\", 'Gnuplot', 'OpenEdge ABL',\n",
        "       'Common Workflow Language', 'Xtend', 'Mercury', 'Genshi',\n",
        "       'Open Policy Agent', 'RobotFramework']]\n",
        "\n",
        "\n",
        "def build_sepereted_term(term_list : List, just_before =False):\n",
        "    if just_before:\n",
        "        sep = \"%s(%s)\" % (term_seperator, \"|\".join(term_list))\n",
        "    else:\n",
        "        sep = \"%s(%s)%s\" % (term_seperator, \"|\".join(term_list), term_seperator)\n",
        "    return sep\n",
        "\n",
        "\n",
        "def build_non_positive_linguistic(positive_re\n",
        "                                  , neg=negation_terms):\n",
        "\n",
        "    non_actionable_context = ['for(?:get|gets|got|getting)'\n",
        "        , 'allow(s|ed|ing)?']\n",
        "\n",
        "\n",
        "    return '(?:%s)' % \"|\".join([\n",
        "        ('(?:%s)' + NEAR_ENOUGH + '(?:%s)') % (build_sepereted_term(modals, just_before=True)\n",
        "                                      ,  positive_re)\n",
        "        , ('(?:%s)' + NEAR_ENOUGH + '(?:%s)') % (build_sepereted_term(neg, just_before=True)\n",
        "                                        ,  positive_re)\n",
        "        , ('(?:%s)' + NEAR_ENOUGH + '(?:%s)') % (build_sepereted_term(non_actionable_context, just_before=True)\n",
        "                                        ,  positive_re)\n",
        "        # TODO - take care of documentation entities spereatly\n",
        "        #, '(?:%s)[\\s\\S]{0,10}(?:%s)' % (build_sepereted_term(documentation_entities, just_before=True)\n",
        "        #                                ,positive_re)\n",
        "    ])\n",
        "\n",
        "\n",
        "def match(commit_text, regex):\n",
        "    text = commit_text.lower()\n",
        "\n",
        "    return len(re.findall(regex, text))\n",
        "\n",
        "\n",
        "def regex_to_big_query(reg_exp\n",
        "                       , text_field='message'):\n",
        "    # TODO - check\n",
        "    # Take care of encoding\n",
        "    reg_exp = reg_exp.replace(\"\\\\\", \"\\\\\\\\\").replace(\"'\", \"\\\\'\")\n",
        "    #reg_exp = reg_exp.replace(\"\\\\\\\\\", \"\\\\\")\n",
        "    # No need for grouping\n",
        "    reg_exp = reg_exp.replace(\"(?:\", \"(\")\n",
        "    str = \"(\" + \"LENGTH(REGEXP_REPLACE(lower(\" + text_field + \"),\" + \"'%s', '@'))\" % reg_exp + \"-\" \\\n",
        "          + \"LENGTH(REGEXP_REPLACE(lower(\" + text_field + \"),\" + \"'%s', ''))\" % reg_exp + \")\"\n",
        "\n",
        "    return str\n",
        "\n",
        "\n",
        "def generate_bq_function(func_name\n",
        "                         , code_generator\n",
        "                         , commit: str ='XXX'):\n",
        "    print(\"# Run in Standard sql \")\n",
        "    print(\"CREATE OR REPLACE FUNCTION \")\n",
        "    print(func_name)\n",
        "    print(\" (message string) \")\n",
        "    print(\" RETURNS int64 \")\n",
        "    print(\"AS (\")\n",
        "    print(\"# Model language based on commit: {commit} \".format(commit=commit))\n",
        "    code_generator()\n",
        "    print(\" ) \")\n",
        "    print(\" ; \")\n",
        "\n",
        "\n",
        "def normalize(string):\n",
        "    string = re.sub(r\"\\s+\", \" \", string.strip())\n",
        "    while \"  \" in string:\n",
        "        string = string.replace(\"  \", \" \")\n",
        "    return string\n",
        "\n",
        "def print_logic_to_bq(regex_func\n",
        "                      , concept):\n",
        "    print(\"# \" + concept)\n",
        "    print( regex_to_big_query(regex_func()))\n",
        "    print(\"# \" + concept + \" - end\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o59-J7ofSwri"
      },
      "source": [
        "Conventional Commit - This filtes the format for conventional commits. Conventional commits is a convention that enforces strict labelling and descriptive message for commits so as they are easily identifyable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azxt3NeBSx1h"
      },
      "source": [
        "cc_adaptive_terms = ['feat' # Feature\n",
        "                        , 'build'\n",
        "                        , 'chore'\n",
        "                        , 'ci' # continuous integration\n",
        "                        , 'test'\n",
        "                        , 'perf' # performance\n",
        "                     ]\n",
        "cc_corrective_terms = ['fix']\n",
        "cc_perfective_terms = ['docs', 'style']\n",
        "cc_refactor_terms = ['refactor']\n",
        "\n",
        "cc_actions = cc_adaptive_terms + cc_corrective_terms + cc_perfective_terms + cc_perfective_terms\n",
        "\n",
        "cc_etc = ['breaking\\s+change(!)?:']\n",
        "\n",
        "\n",
        "def cc_title(astions):\n",
        "\n",
        "    return '^(' + \"|\".join(astions) +\")(\\(.*\\))?(!)?:\"\n",
        "\n",
        "\n",
        "# Adaptive\n",
        "def build_cc_adaptive_regex():\n",
        "\n",
        "    return cc_title(cc_adaptive_terms)\n",
        "\n",
        "\n",
        "def is_cc_adaptive(commit_text):\n",
        "\n",
        "    return len(re.findall(build_cc_adaptive_regex(), commit_text)) > 0\n",
        "\n",
        "\n",
        "# Corrective\n",
        "def build_cc_corrective_regex():\n",
        "\n",
        "    return cc_title(cc_corrective_terms)\n",
        "\n",
        "\n",
        "def is_cc_corrective(commit_text):\n",
        "\n",
        "    return len(re.findall(build_cc_corrective_regex(), commit_text)) > 0\n",
        "\n",
        "# Refactor\n",
        "def build_cc_refactor_regex():\n",
        "\n",
        "    return cc_title(cc_refactor_terms)\n",
        "\n",
        "\n",
        "def is_cc_refactor(commit_text):\n",
        "\n",
        "    return len(re.findall(build_cc_refactor_regex(), commit_text)) > 0\n",
        "\n",
        "# Just Perfective\n",
        "def build_cc_just_perfective_regex():\n",
        "\n",
        "    return cc_title(cc_perfective_terms)\n",
        "\n",
        "\n",
        "def is_cc_just_perfective(commit_text):\n",
        "\n",
        "    return len(re.findall(build_cc_just_perfective_regex(), commit_text)) > 0\n",
        "\n",
        "# Perfective\n",
        "def build_cc_perfective_regex():\n",
        "\n",
        "    return \"(\" + \"|\".join([build_cc_refactor_regex()\n",
        "                              , build_cc_just_perfective_regex()]) + \")\"\n",
        "\n",
        "\n",
        "def is_cc_perfective(commit_text):\n",
        "\n",
        "    return len(re.findall(build_cc_perfective_regex(), commit_text)) > 0\n",
        "\n",
        "# CC message\n",
        "def build_cc_message_regex():\n",
        "\n",
        "    return \"(\" + \"|\".join([cc_title(cc_actions)] + cc_etc) + \")\"\n",
        "\n",
        "\n",
        "\n",
        "def is_cc_message(commit_text):\n",
        "\n",
        "    return len(re.findall(build_cc_message_regex(), commit_text)) > 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def print_cc_functions_for_bq(commit: str = 'XXX'):\n",
        "\n",
        "    concepts = {'cc_adaptive' : build_cc_adaptive_regex\n",
        "                , 'cc_corrective' : build_cc_corrective_regex\n",
        "                , 'cc_refactor' : build_cc_refactor_regex\n",
        "                , 'cc_just_perfective' : build_cc_just_perfective_regex\n",
        "                , 'cc_perfective' : build_cc_perfective_regex\n",
        "                , 'cc_message' : build_cc_message_regex\n",
        "                }\n",
        "\n",
        "    for i in concepts.keys():\n",
        "        print()\n",
        "        print_func = lambda : print_logic_to_bq(regex_func=concepts[i]\n",
        "                                                , concept=i)\n",
        "        generate_bq_function('{schema}.bq_{concept}'.format(schema=SCHEMA_NAME\n",
        "                                                            , concept=i)\n",
        "                             , print_func\n",
        "                             , commit=commit)\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8orw-O5iS3kx"
      },
      "source": [
        "**Corrective/Bug**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9czkOj1mTCWp"
      },
      "source": [
        "Keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At-KgpUXS8UZ"
      },
      "source": [
        "core_bug_terms = [\n",
        "             'bug(s|z)?',\n",
        "             'bug(?:-|\\s)?fix(es)?',\n",
        "             'defect(?:s)?',\n",
        "             'error(?:s)?',\n",
        "             'failur(?:ing|e|es|ed)',\n",
        "             'fault(s)?',\n",
        "             'fix(ed|es|ing)?',\n",
        "             'fixing(?:s)?',\n",
        "             'incorrect(ly)?',\n",
        "             'mistake(s|n|d|nly)?',\n",
        "             'problem(?:s)?',\n",
        "             ]\n",
        "# Positive\n",
        "bug_terms = ['actual.*expected',\n",
        "             '((assignment|assign|=) in if|== instead of =)',\n",
        "             'expected.*actual'\n",
        "             '(choose|take|set|use)\\\\s*(the|a)?\\\\s*correct', # correct as adjective\n",
        "             \"(not|isn't|doesn't)\\\\s+work(s|ing)?\", # TODO - check with negation\n",
        "             \"doesn't recognize\", # TODO Extend\n",
        "             'double(?:-| )allocat(?:e|ion|ions)',\n",
        "             'double(?:-| )free(?:s)?',\n",
        "             \"caused a regression\", # TODO Extend\n",
        "             'bad initialization(?:s)?',\n",
        "             'buffer overflow(?:s)?',\n",
        "             'fixme(?:s)?',\n",
        "             'fixes(?:-| )?commit(?::| )?',\n",
        "             '(break|breaks|broke|broked|breaking|broken)[\\s\\S]{0,20}(code|system|function|method)',\n",
        "             '(this|that|it)\\s(break|breaks|broke|broked|breaking|broken)',\n",
        "             'break strict(?:-|\\s)aliasing rule(s)?',\n",
        "             'crash(?:ing|s|ed)?',\n",
        "             'correct(?:ing|s|ed)?\\\\s*(a|the|some|few|this)', # make sure that correct serves as a verb\n",
        "             'correct(ed|ion|ly|s)?',\n",
        "             '(dangling|hanging) pointer(?:s)?',\n",
        "             'deadlock(?:s)?',\n",
        "             '(divid(e|es|ed|ing)|division) by (zero|0)',\n",
        "             'double(?:-| )free',\n",
        "             'fail(?:ing|s|ed)?',\n",
        "             'faulty initialization(?:s)?',\n",
        "             'fix(?:-| )?in(?:s)?',\n",
        "             'fix(?:-| )?up(?:s)?',\n",
        "             'flaw(?:s|ed)?',\n",
        "             '(float|integer) (under|over)(?:-| )?flow',\n",
        "             'hot(?:-| )?fix(?:ed|es|ing)?',\n",
        "             #'hang',\n",
        "             'heap overflow(?:s)?',\n",
        "             '(?:im|im-)?proper'\n",
        "             'memory(?:-| )?leak(?:s)?',\n",
        "             'missing\\s(default value|initialization|switch case)(?:s)?',\n",
        "             'is\\smissing',\n",
        "             'add(?:ing|s|ed)?\\smiss(?:ing|es|ed)?',\n",
        "             #'must not',\n",
        "             'npe(?:s)?'\n",
        "             'null pointer(?:s)?',\n",
        "             'off(?:-| )by(?:-| )(one|1)',\n",
        "             'out of bound(?:s)?',\n",
        "             'over(?:-| )?run(?:s)?',\n",
        "             'patch(?:ed|ing)',\n",
        "             #'prevent(?:ing|s|ed)?', # should be tuned\n",
        "             'race condition(?:s)?',\n",
        "             'data race(?:s)?',\n",
        "             'repair(?:ing|s|ed)?',\n",
        "             'resource leak(?:s)?',\n",
        "             # TODO - check generalization to leaks works in the other direction to expected (reduces FP, increases FN)\n",
        "             'leak(?:s)?',\n",
        "             'revert(?:ing|s|ed)?',\n",
        "             'segmentation (fault|violation)(?:s)?',\n",
        "             'resolv(?:ing|e|es|ed)',\n",
        "             #'solv(?:ing|e|es|ed)',\n",
        "             'workaround(?:s)?',\n",
        "             'wrong(nly)?',\n",
        "             '(type(s)? mis(?:-| )?match|(not|non|none) matching type(s)?)',\n",
        "             'trouble(?:s)?',\n",
        "             '(un(?:-| )?|not )initialized variable(s)?',\n",
        "             'unintended',\n",
        "             'not intended',\n",
        "             'unintentionally',\n",
        "             'not intentionally',\n",
        "             # 'unexpected.*occurred', # very rare, 90% are bugs anyway\n",
        "             'vulnerabilit(?:y|ies)'\n",
        "             ] + core_bug_terms\n",
        "\n",
        "# Valid_fix_objects\n",
        "valid_fix_object = prefective_entities + ['#',\n",
        "                    '(camel|snake|kebab|flat|lower|upper)\\\\s*case',\n",
        "                    \"code review('s|s)?\",\n",
        "                    'comment(?:s)?',\n",
        "                    'cosmetic(?:s)?',\n",
        "                    'cr(s)?(?:-)?',\n",
        "                    'documentation(?:s)?',\n",
        "                    #'exception(?: |-)?handling',\n",
        "                    #'format(s|ing)? fix(ed|es|ing)?',\n",
        "                    'format(?:ing)?',\n",
        "                    'help',\n",
        "                    'remark(s)?',\n",
        "                    'space(s)?',\n",
        "                    'style|styling',\n",
        "                    'typo(s)?',\n",
        "                    'typing(?: |-)?(error|mistake)(s)?',\n",
        "                    'warning(s)?',\n",
        "                    'white(?: |-)?space(s)?']\n",
        "\n",
        "valid_terms = [\n",
        "    'break\\sout',\n",
        "    'error(?: |-)?check(ing)?',\n",
        "    'error(?: |-)?handling',\n",
        "    'error message(s)?',\n",
        "    'error report(s|ing)?',\n",
        "    'fixed(?: |-)?point',\n",
        "    'fix(?:ed) ticket(?:s)?',\n",
        "    #'format(ing)?',\n",
        "    '(?:fix(?:ed|es)?|bug)(?: )?(?: |-|=|:)(?: )?[a-z]{0,3}(?:-)?\\d+' + term_seperator,\n",
        "    '(if|would)[\\s\\S]{0,40}go wrong',\n",
        "    'line(?:s)? break(?:s)?',\n",
        "    'typo(s)?\\sfix(es)?',\n",
        "    'fix(ed|es|ing)?' + build_sepereted_term(software_entities) + 'name(s)?',\n",
        "    build_sepereted_term(static_analyzers) + 'fix(es|ed)?',\n",
        "    'fix(es|ed)?' + build_sepereted_term(static_analyzers) ,\n",
        "    '^### Bug Fix', # tends to be a title, later stating if the commit is a bug fix\n",
        "    'edit the jira link to the correct issue', # Another occurring title\n",
        "    'page(?:s)? break(?:s)?',\n",
        "\n",
        "\n",
        "] + code_review_fixes\n",
        "\n",
        "\n",
        "\n",
        "fixing_verbs = ['correct(?:ing|s|ed)'\n",
        "                    , 'fix(ed|s|es|ing)?'\n",
        "                    , 'repair(?:ing|s|ed)?'\n",
        "                    ,  'revert(?:ing|s|ed)?'\n",
        "                    , 'resolv(?:ing|e|es|ed)'\n",
        "                    , 'revok(?:ing|e|es|ed)'\n",
        "                    , 'und(?:oing|id)'\n",
        "                ]\n",
        "MERGE_PREFIX = '(merge (branch|pull request).{0,25}|merge (branch|pull request).{0,25}(from|into).{0,25})'\n",
        "END_OF_LINE = r'(\\r\\n|\\r|\\n|$)'\n",
        "corrective_header_entities = fixing_verbs + [\n",
        "    'miss(?:ing|es|ed)?', 'should', 'must', '(have|has) to', 'avoid', 'prevent', 'break(s|ed|ing)?', 'broken'\n",
        "    , 'remov(?:ing|e|es|ed) change(?:s)?', 'unable', 'proper(?:ly)?'\n",
        "    , MERGE_PREFIX + \"(%s)\" % \"|\".join(core_bug_terms) + '.{0,250}' + END_OF_LINE\n",
        "    #, \"(does not|doesn't) need\" , \"cannot\", \"can not\"\n",
        " ] #+ [ \"do not\" ,\"don't\", \"dont\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPb7SQbtTLKx"
      },
      "source": [
        "Regex Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4xrkWWETNyp"
      },
      "source": [
        "def build_sepereted_term(term_list : List, just_before =False):\n",
        "    if just_before:\n",
        "        sep = \"%s(%s)\" % (term_seperator, \"|\".join(term_list))\n",
        "    else:\n",
        "        sep = \"%s(%s)%s\" % (term_seperator, \"|\".join(term_list), term_seperator)\n",
        "    return sep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OH36QjPTTrR"
      },
      "source": [
        "def build_valid_find_regex():\n",
        "    fix_re = \"(\" + \"|\".join(fixing_verbs + [MERGE_PREFIX]) + \")\"\n",
        "    prefix = term_seperator + fix_re + '[\\s\\S]{1,40}' + \"(\" + \"|\".join(valid_fix_object) + \")\" + term_seperator\n",
        "\n",
        "    suffix = term_seperator + \"(\" + \"|\".join \\\n",
        "        (valid_fix_object) + \")\" + term_seperator + '[\\s\\S]{0,40}' + term_seperator + fix_re + term_seperator\n",
        "\n",
        "    # TODO - check seperation\n",
        "    #sepertion = '(?:%s|%s[\\s\\S]{0,40}%s)' % (term_seperator, term_seperator, term_seperator)\n",
        "    #suffix = \"(\" + \"|\".join \\\n",
        "    #    (valid_fix_object) + \")\" + sepertion + fix_re + term_seperator\n",
        "\n",
        "    #other_valid_re = \"(%s)\" % \"|\".join(valid_terms)\n",
        "    other_valid_re = build_sepereted_term(valid_terms)\n",
        "    return \"((%s)|(%s)|(%s))\" % (prefix, suffix, other_valid_re)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAY3ir69Tm6p"
      },
      "source": [
        "def build_bug_fix_regex(use_conventional_commits=True):\n",
        "    header_regex =  '(?:^|^[\\s\\S]{0,25}%s)(?:%s)%s' % (term_seperator\n",
        "                                                       , \"|\".join(corrective_header_entities)\n",
        "                                                       , term_seperator)\n",
        "   # strict_header = \"^(?:%s)%s\"  % ( \"|\".join([ \"do not\" ,\"don't\"])\n",
        "   #                                                    , term_seperator)\n",
        "\n",
        "    bug_fix_re = build_sepereted_term(bug_terms)\n",
        "\n",
        "\n",
        "    if use_conventional_commits:\n",
        "        agg_re = \"((%s)|(%s)|(%s))\" % (bug_fix_re, header_regex, build_cc_corrective_regex())\n",
        "    else:\n",
        "        agg_re = \"((%s)|(%s))\" % (bug_fix_re, header_regex)\n",
        "\n",
        "    return agg_re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7eviiFnTuEI"
      },
      "source": [
        "def build_negeted_bug_fix_regex():\n",
        "    bug_fix_re = build_bug_fix_regex(use_conventional_commits=False)\n",
        "    negation_re = build_sepereted_term(negation_terms)\n",
        "\n",
        "\n",
        "    return \"%s[\\s\\S]{0,20}%s\" % (negation_re, bug_fix_re)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA56FqIpTvzh"
      },
      "source": [
        "def build_core_bug_regex():\n",
        "\n",
        "    return '(%s)' % build_sepereted_term(core_bug_terms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm600Y4FUmvQ"
      },
      "source": [
        "**Security**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2RECbBAUq3_"
      },
      "source": [
        "Keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF-b89FVUrko"
      },
      "source": [
        "positive_terms = [\n",
        " 'advisory',\n",
        " 'attack(?:s)?',\n",
        " 'auth',\n",
        " 'authenticat(e|ion)',\n",
        " 'brute force', # consider\n",
        " 'bug bount(y|ies)',\n",
        " 'bypass(?:es|ed|ing)?', # consider\n",
        " 'certificate(?:s)?',\n",
        " #'constant time', # too general\n",
        " 'crack',\n",
        " 'credential(s)?',\n",
        " 'cross(?: |-)origin',\n",
        " 'cross(?: |-)site',\n",
        " 'cve(-d+)?(-d+)?',\n",
        " 'clickjack',\n",
        " 'cyber',\n",
        " 'denial of service',\n",
        " '(de)?serializ', # consider\n",
        " 'directory traversal',\n",
        " 'dos', # consider\n",
        " 'exploit',\n",
        " #'expos(e|ing)',\n",
        " # 'hack', # A bit general, consider\n",
        " 'hijack',\n",
        " 'harden',\n",
        " #'infinite loop', # consider\n",
        " 'injection',\n",
        " '(in)?secur(e|ity)',\n",
        " 'lockout',\n",
        " 'malicious',\n",
        " 'malware(?:s)?', #plural of malware is malware yet not all are aware\n",
        " 'nvd' # NVD\n",
        " 'open redirect',\n",
        " 'osvdb', # OSVDB\n",
        " 'overflow', # consider\n",
        " 'password(?:s)?',\n",
        " 'permission(?:s)?',\n",
        " 'poison(?:s|es|ed|ing)?',\n",
        " 'port scan',\n",
        " 'privilege(?:s)?',\n",
        " # 'proof of concept', # consider\n",
        " 'rce', # remote code execution\n",
        " 'redos' # ReDoS\n",
        " 'remote code execution',\n",
        " 'return oriented programming',\n",
        " '(?:safe|safety|unsafe|safer)',\n",
        " 'security',\n",
        " 'session fixation',\n",
        " 'spoof(?:s|es|ed|ing)?',\n",
        " 'threat(?:s|ed|ing)?',\n",
        " 'timing', # consider\n",
        " 'token(?:s)?',\n",
        " #'traversal',\n",
        " 'unauthori[z|s]ed',\n",
        " 'vulnerabilit(?:y|ies)',\n",
        " 'x(?: |-)frame(?: |-)option(?:s)?',\n",
        " 'xss',\n",
        " 'xsrf', # XSRF\n",
        " 'xxe' # XXE\n",
        "    ]\n",
        "\n",
        "excluded_terms = ['_____PLACEHOLDER_____'\n",
        "                  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14mjQVf3UuLo"
      },
      "source": [
        "Regex Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBw3rrRJUvUA"
      },
      "source": [
        "def build_positive_regex():\n",
        "\n",
        "    return build_sepereted_term(positive_terms)\n",
        "\n",
        "\n",
        "\n",
        "def build_excluded_regex():\n",
        "\n",
        "    return build_sepereted_term(excluded_terms)\n",
        "\n",
        "def build_not_positive_regex():\n",
        "\n",
        "    return build_non_positive_linguistic(build_positive_regex())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xkk-fAKBVIhg"
      },
      "source": [
        "**Other**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGVXoFOtVKeY"
      },
      "source": [
        "Keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jlo0qXKVNrI"
      },
      "source": [
        "core_adaptive_terms = [\n",
        "    'add(?:s|ed|ing)?',\n",
        "    'creat(?:e|es|ing)',\n",
        "    'disabl(?:e|es|ed|ing)',\n",
        "    'implement(?:ed|s|ing)?',\n",
        "    'import(?:s|ed|ing)?',\n",
        "    'introduc(?:e|es|ed|ing)',\n",
        "    'port(?:s|ed|ing)?',\n",
        "    'provid(?:e|es|ed|ing)',\n",
        "    'updat(?:e|es|ed|ing)',\n",
        "    'upgrad(?:e|es|ed|ing)'\n",
        "\n",
        "]\n",
        "\n",
        "adaptive_context = [\n",
        " '(?:un)?hid(?:e|es|den)',\n",
        " 'allow(?:s|ed|ing)?',\n",
        " 'buil(?:t|ds|ing)',\n",
        " 'calibirat(?:e|es|ed|ing)',\n",
        " 'configure',\n",
        " 'deferr(?:ed|s|ing)?',\n",
        " 'enhanc(?:e|es|ed|ing)',\n",
        " 'extend(?:s|ed|ing)?',\n",
        " 'form(?:ed|s|ing)?',\n",
        " 'report(?:s|ed|ing)?',\n",
        " 'support(s|ed|ing)?',\n",
        "\n",
        "# , 'mov(e|es|ed|ing)'\n",
        "# , 'print(s|ed|ing)?'\n",
        "\n",
        "] + core_adaptive_terms\n",
        "\n",
        "\n",
        "\n",
        "adaptive_entities = ['ability', 'configuration', 'conversion', 'debug', 'new', 'possibility', 'support'\n",
        "    , 'test(s)?', 'tweak(s)?', 'mode', 'option']\n",
        "\n",
        "\n",
        "adaptive_header_action = \"|\".join([\n",
        "    'upgrad(?:e|es|ed|ing)',\n",
        "    'configur(?:e|es|ed|ing)',\n",
        "    'chang(?:e|es|ed|ing)',\n",
        "    '(?:keep|change)\\s+(?:the\\s+)?default',\n",
        "    'new',\n",
        "    # '(?:make(?:s)?|made|making)',\n",
        "    'merg(?:e|es|ed|ing)',\n",
        "    'clear(?:s|ed|ing)?',\n",
        "    #'comment(?:s|ed|ing)?\\sout'\n",
        "    'creat(?:e|es|ed|ing)',\n",
        "    'cast(?:s|et|ing)?' + NEAR_ENOUGH + '\\sas',\n",
        "    # 'convert(?:s|ed|ing)?',\n",
        "    # 'check(?:s|ed|ing)?',\n",
        "    'add(?:s|ed|ing)?',\n",
        "    # 'buil(?:d|t|ds|ing)',\n",
        "    'Initial revision',\n",
        "    '(?:im)?port(?:s|ed|ing)?',\n",
        "    '(?:un)?hid(?:e|es|den)',\n",
        "    'updat(?:e|es|ed|ing)',\n",
        "    'upload(?:s|ed|ing)?',\n",
        "    'disabl(?:e|es|ed|ing)',\n",
        "    'delet(?:e|es|ed|ing)',\n",
        "    'enabl(?:e|es|ed|ing)',\n",
        "    'quirk(?:s|ed|ing)?',\n",
        "    'skip(?:s|ed|ing)?',\n",
        "    'switch(?:s|ed|ing)?',\n",
        "    'allow(?:s|ed|ing)?',\n",
        "    'provid(e|es|ed|ing)',\n",
        "\n",
        "    ###\n",
        "    # , 'build'\n",
        "    # , 'mark(?:s|ed|ing)?'\n",
        "    # , 'us(?:e|es|ed|ing)'\n",
        "    # , '(?:make|made|making)'\n",
        "    # , 'creat(?:e|es|ed|ing)'\n",
        "    # , 'handl(?:e|es|ed|ing)'\n",
        "    'remov(?:e|es|ed|ing)',\n",
        "    'refresh(?:s|ed|ing)?',\n",
        "    #'re(-)?enabl(?:e|es|ed|ing)',\n",
        "\n",
        "] +no_message\n",
        ")\n",
        "\n",
        "adaptive_actions = [  # 'revert(?:s|ed|ing)?',\n",
        "    #'merg(?:e|es|ed|ing)[\\s\\S]{1,5}(pull request|pr|branch)',\n",
        "    'add(?:s|ed|ing)?[\\s\\S]{1,50}(?:version|v\\d|ver\\d)',\n",
        "    #'(cr(s)?(-)?|code\\sreview)\\sfix(?:s|ed|ing)?',\n",
        "    '(^|\\s)implement(?:ed|s|ing)?\\s',\n",
        "    '(?:make(?:s)?|made|making)[\\s\\S]{1,50}consitent',\n",
        "    'updat(?:e|es|ed|ing)[\\s\\S]{1,25}to[\\s\\S]{1,25}\\d+.\\d',\n",
        "    'updat(?:e|es|ed|ing)\\s+(to\\s+)?\\d+\\.\\d',\n",
        "    '(?:add(s|ed|ing)?|delet(?:e|es|ed|ing)|updat(?:e|es|ed|ing))\\s+' + file_scheme,\n",
        "    # '(add(s|ed|ing)?|delet(e|es|ed|ing)|updat(e|es|ed|ing))\\s+([A-Z0-9_]*)', # TODO - run without lower\n",
        "    '(^|^[\\s\\S]{0,25}%s)(%s)%s' % (term_seperator, adaptive_header_action, term_seperator),\n",
        "    # '^(?:version|v\\d+\\.\\d|ver\\d+\\.\\d)',\n",
        "    '^\\[(?:IMP|imp)\\]',  # TODO - take care of upper/lower case\n",
        "    'support(?:s|ed|ing)?\\sfor\\s',\n",
        "    'show(?:es|ed|ing)?[\\s\\S]instead',\n",
        "    'scal(?:e|es|ed|ing)?\\s(up|down)'\n",
        "\n",
        "                   ] + code_review_fixes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J_rj8KJV0Pw"
      },
      "source": [
        "def build_adaptive_action_regex():\n",
        "\n",
        "    return \"(%s)\" % (\"|\".join(\n",
        "    adaptive_actions))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_adaptive_regex(use_conventional_commits=True):\n",
        "\n",
        "    adaptive_context_re = build_sepereted_term(adaptive_context, just_before=True)\n",
        "\n",
        "\n",
        "    base_re = \"((%s)\\s[\\s\\S]{0,50}(%s)%s)\" % (adaptive_context_re\n",
        "                            ,  \"|\".join(adaptive_entities + software_terms)\n",
        "                            , term_seperator)\n",
        "\n",
        "    if use_conventional_commits:\n",
        "        agg_re = \"((%s)|(%s))\" % (base_re\n",
        "                                  , build_cc_adaptive_regex())\n",
        "    else:\n",
        "        agg_re = base_re\n",
        "\n",
        "    return agg_re\n",
        "\n",
        "\n",
        "\n",
        "def build_non_adaptive_context():\n",
        "\n",
        "    non_adaptive_header_action = \"|\".join([\n",
        "                                'transla(?:tion|et|eted|ets|ting)'\n",
        "                                ,  'readme(?:.md)?'\n",
        "                              ])\n",
        "\n",
        "    non_adaptive_header ='^[\\s\\S]{0,50}(%s)' % non_adaptive_header_action\n",
        "\n",
        "    entities = documentation_entities + ['bug',\n",
        "                'helper',\n",
        "                'miss(?:ing|ed)',\n",
        "                'to(?: |-)?do(?:s)?',\n",
        "                'warning(?:s)?'\n",
        "                ]\n",
        "\n",
        "    adaptive_actions = ['remov(?:e|es|ed|ing)']\n",
        "    non_adaptive_entities = documentation_entities + software_terms + unnedded_terms + [file_scheme]\n",
        "\n",
        "\n",
        "    return '(%s)' % \"|\".join(['(?:%s)\\s[\\s\\S]{0,50}(?:%s)' % (build_sepereted_term(adaptive_context, just_before=True)\n",
        "                                                            , \"|\".join(entities))\n",
        "                     , non_adaptive_header\n",
        "                     , '(?:%s)\\s[\\s\\S]{0,50}(?:%s)' % (build_sepereted_term(adaptive_actions, just_before=True)\n",
        "                                                            , \"|\".join(non_adaptive_entities))\n",
        "                     ])\n",
        "\n",
        "\n",
        "def build_non_adaptive_linguistic():\n",
        "\n",
        "    return build_non_positive_linguistic(build_adaptive_regex(use_conventional_commits=False))\n",
        "\n",
        "def build_core_adaptive_regex():\n",
        "\n",
        "    return '(%s)' % build_sepereted_term(core_adaptive_terms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vliNqCXgWGMA"
      },
      "source": [
        "**Refactor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoLnoN5kWMog"
      },
      "source": [
        "Keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-p2Vlv1WNba"
      },
      "source": [
        "# https://arxiv.org/pdf/2002.11049.pdf\n",
        "refactor_entities = software_terms + ['(helper|utility|auxiliary) function(?:s)?']\n",
        "\n",
        "\n",
        "# Well, we need them...\n",
        "unnedded_terms = ['unnecessary', 'unneeded', 'unused', '(?:not|never|no longer) used'\n",
        "    #, 'old'\n",
        "    , 'no longer needed', 'redundant', 'useless', 'duplicate(?:d)?', 'deprecated', 'obsolete(?:d)?', 'commented']\n",
        "\n",
        "core_refactor_terms = [\n",
        "    'clean(?:ing)?(?:-| )?up(?:s)?',\n",
        "    'clean(?:ing|s|ed)?',\n",
        "    'combin(?:e|es|ed|ing)',\n",
        "    'compos(?:e|es|ed|ing)',\n",
        "    'de(?:-| )?compos(?:e|es|ed|ing)',\n",
        "    'deprecat(?:e|es|ed|ing)',\n",
        "    'encapsulat(?:e|es|ed|ing)',\n",
        "    'polish(?:ed|es|ing)?',\n",
        "    're(?:-| )?factor(?:ed|s|ing|ings)?', # TODO - should be here - check why slightly decreases performance\n",
        "    're(?:-|)?organiz(?:e|es|ed|ing)',\n",
        "    're(?:-|)?structur(?:e|es|ed|ing)',\n",
        "    'rebuil(?:d|ds|ding|t)',\n",
        "    'tid(?:y|ying|ied)'\n",
        "]\n",
        "\n",
        "\n",
        "modification_activity = [\n",
        "'(?:get|got|getting) rid',\n",
        " '(?:make|makes|made|making)',\n",
        " 'convert(?:ed|s|ing)?',\n",
        " 'dead',\n",
        " 'drop(?:ed|s|ing)?',\n",
        " 'duplicat(?:e|es|ed|ing)',\n",
        " 'extract(?:ed|s|ing)?',\n",
        " 'hide(?:e|es|ed|ing)',\n",
        " 'improv(?:e|es|ed|ing)',    # Goals modification only?\n",
        " 'increas(?:e|es|ed|ing)',\n",
        " 'mov(?:e|es|ed|ing)',\n",
        " 'parameteriz(?:e|es|ed|ing)',\n",
        " 'redundant',\n",
        " 'replac(?:e|es|ed|ing)',\n",
        " 'separat(?:e|e s|ed|ing)',\n",
        " 'short(:?en|er|ing|s)?',\n",
        " 'split(?:s|ing)?',\n",
        " 'subsitut(?:e|es|ed|ing)',\n",
        " 'substitut(?:e|es|ed|ing)',\n",
        " 'un(?:-| )?hid(?:e|es|ed|ing)'\n",
        "\n",
        "    #'chang(?:e|esed|ing)'\n",
        "    #, 'creat(?:e|es|ed|ing)'\n",
        "    #, 'delet(?:e|es|ed|ing)'\n",
        "    #, 'instead'\n",
        "    #, 'kill(?:ed|s|ing)?'\n",
        "    # , 'provid(?:e|es|ed|ing)'\n",
        "    #, 'introduc(?:e|es|ed|ing)'\n",
        "] + core_refactor_terms + unnedded_terms\n",
        "\n",
        "feedbak_terms = [ 'py(?:-| )?lint', 'lint', 'review comments(?:s)?', 'code review', 'cr', 'pep8'\n",
        "                  ]\n",
        "feedback_action = ['fix(?:ed|s|es|ing)?', 'fix(?:-| )?up(?:s)?', 'resolv(?:e|ed|es|ing)', 'correct(?:ed|s|es|ing)?']\n",
        "\n",
        "perfective_header_action = [\n",
        "    #'polish(?:ed|es|ing)?'\n",
        "    #, 'clean(?:ing|s|ed)?(?:-| )?up(?:s)?'\n",
        "     'clean(?:ing|s|ed)?(?:-| )?up(?:s)?'\n",
        "    , 'cleaner'\n",
        "    , 'deprecat(?:e|es|ed|ing)'\n",
        "    , 'extract(?:ed|s|ing)?',\n",
        "    're(?:-|)?organiz(?:e|es|ed|ing)', 're(?:-|)?structur(?:e|es|ed|ing)', 'tid(?:y|ying|ied) up'\n",
        "    , 'improv(?:e|ed|es|ing|ement|ements)' , 're(?:-|)?organiz(?:e|es|ed|ing)', 're(?:-|)?structur(?:e|es|ed|ing)'\n",
        "    , '(helper|utility|auxiliary) function(?:s)?'\n",
        "    , '(?:move|moved|moves|moving) to'\n",
        "    , 'separat(?:e|es|ed|ing)'\n",
        "    , 'split(?:s|ing)?', '->'\n",
        "    , build_sepereted_term(static_analyzers) + 'fix(es|ed)?'\n",
        "    , 'fix(es|ed)?' + build_sepereted_term(static_analyzers)\n",
        "\n",
        "    #, '(private|public|protected|static)'\n",
        "]\n",
        "\n",
        "# TODO - rewrited, move into/out???, deduplicate, remove legacy, redo, PR, feedback\n",
        "\n",
        "# TODO - clean , style, prettier, \"->\", refine, \"Removed commented code\", \"More startup improvements.\", recode\n",
        "# \"\"Remove another old function\", \"improved redis error message\", utility functions, never used\n",
        "# Checkstyle\n",
        "\n",
        "\n",
        "# TODO - perfective, not refactor - ident, spacing, tabs, \"tabs -> spaces\", cosmetic, \"\"*** empty log message ***\"\n",
        "# examples \"\"DOC: remove mention of TimeSeries in docs\"\n",
        "\n",
        "# TODO - add \"resolving review comments\"\n",
        "# TODO - lint, pylint\n",
        "refactor_context = [ 'clean(ing)?(-| )?up(s)?'\n",
        "    ,'call(?:s|ed|ing)?[\\s\\S]{1,50}instead'\n",
        "    , 'collaps(?:e|es|ed|ing)', 'consolidat(e|es|ed|ing)'\n",
        "    , 'decompos(?:e|es|ed|ing)'\n",
        "    , 'drop(?:ed|s|ing)?( back)', 'encapsulat(e|es|ed|ing)'\n",
        "    , 'gereneliz(?:e|es|ed|ing)'\n",
        "                    # , 'inline'\n",
        "                    # , 'no longer needed', 'not used', 'obsolete(d)?'\n",
        "    , 'optimiz(?:e|es|ed|ing|ation|ations)'\n",
        "    , 'pull(?:ed|s|ing)? (up|down)', 're(?:-)?(?:write|wrote)', 're(?:-| )?factor(?:ed|s|ing|ings)?'\n",
        "    , 're(-)?implement(ed|s|ing)?'\n",
        "    , 'renam(?:e|es|ed|ing|ings)', 'better nam(?:e|es|ing)','re(?:-)?organiz(e|es|ed|ing)', 're(?:-)?organization'\n",
        "    , 're(?:-)?work(ed|s|ing|ings)?'\n",
        "    , 'reorg' , 'simplif(y|es|ied|ying|ication)', 'suppress(es|ed|ing)? warning(?:s)?'\n",
        "    , 'unif(?:y|ies|ied|ing)', 'uninline'\n",
        "    , 'beef(?:ed|s|ing)? up', 'refactor(?:ing)?(?:s)?', 'code improvement(?:s)?'\n",
        "    #, '(?:^|^[\\s\\S]{0,25}%s)(?:%s)%s[\\s\\S]{0,25}$' % (term_seperator, \"|\".join(perfective_header_action), term_seperator)\n",
        "    , 'revis(?:e|es|ed|ing)'\n",
        "    , 're(?:-)?construct(?:s|ed|ing)?'\n",
        "    , 're(?:-)?(?:write|write|wrote|writing)'\n",
        "    , 're(?:-)?cod(?:e|ed|es|ing)'\n",
        "    , 'factor(?:ed|s|ing)? out'\n",
        "    , 're(?:-| )?packag(?:e|es|ed|ing)'\n",
        "    #, 'code review'\n",
        "    #, 'collapse'\n",
        "    #, \"(?:(?:%s)(?:%s|%s[\\s\\S]{0,50}%s)(?:%s)%s)\" % (build_sepereted_term(feedback_action\n",
        "    #                                                                                      , just_before=True)\n",
        "    #                                                                 , term_seperator\n",
        "    #                                                                 , term_seperator\n",
        "    #                                                                 , term_seperator\n",
        "    #                                                                 , \"|\".join(feedbak_terms)\n",
        "    #                                                                 , term_seperator)\n",
        "                    # ,'us(e|es|ed|ing)[\\s\\S]{1,50}(instead)'\n",
        "                    # , '(instead)[\\s\\S]{1,50}us(e|es|ed|ing)'\n",
        "                    ]\n",
        "# https://refactoring.guru/refactoring/techniques\n",
        "\n",
        "# TODO - change [\\s\\S] with . ?\n",
        "removal = [ 'add(?:s|ed|ing)?[\\s\\S]{1,50}helper(?:s)?'\n",
        "    ,  'us(?:e|es|ed|ing)[\\s\\S]{1,50}instead'\n",
        "    #,  'us(?:e|es|ed|ing)[\\s\\S]{1,25}\\(\\)[\\s\\S]{1,25}instead'\n",
        "    ,  'split(?:s|ing)?[\\s\\S]{1,50}into'\n",
        "    ,  'break(?:s|ing)?[\\s\\S]{1,50}into'\n",
        "    ,  'separat(?:e|e s|ed|ing)[\\s\\S]{1,50}into'\n",
        "    #,  'replac(?:e|es|ed|ing)?[\\s\\S]{1,50}with'\n",
        "    ,  'replac(?:e|es|ed|ing)?[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n",
        "    , 'remov(?:e|es|ed|ing)[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n",
        "    #, '(?:this|that|is)[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n",
        "    ,  'kill(?:s|ed|ing)?[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n",
        "    ,  'drop(?:s|ed|ing)?[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n",
        "    ,  'mov(?:e|es|ed|ing)?[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n",
        "            ]\n",
        "adaptive_context = [\n",
        "    '(?:un)?hid(?:e|es|den)', 'add(?:s|ed|ing)?', 'allow(?:s|ed|ing)?'\n",
        "    , 'buil(?:t|ds|ing)', 'calibirat(?:e|es|ed|ing)'\n",
        "    , 'configure'\n",
        "    , 'creat(?:e|es|ing)' #   O created\n",
        "    , 'deferr(?:ed|s|ing)?'\n",
        "    , 'disabl(?:e|es|ed|ing)'\n",
        "    , 'enhanc(?:e|es|ed|ing)', 'extend(?:s|ed|ing)?', 'form(?:ed|s|ing)?'\n",
        "    , 'implement(?:ed|s|ing)?', 'import(?:s|ed|ing)?', 'introduc(?:e|es|ed|ing)'\n",
        "    , 'port(?:s|ed|ing)?'\n",
        "    , 'provid(?:e|es|ed|ing)'\n",
        "    , 'report(?:s|ed|ing)?'\n",
        "    , 'support(s|ed|ing)?'\n",
        "    , 'updat(?:e|es|ed|ing)'\n",
        "    , 'upgrad(?:e|es|ed|ing)'\n",
        "\n",
        "    # , 'mov(e|es|ed|ing)'\n",
        "    # , 'print(s|ed|ing)?'\n",
        "\n",
        "\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFTsrbrFWQwY"
      },
      "source": [
        "def build_core_refactor_regex():\n",
        "\n",
        "    return '(%s)' % build_sepereted_term(core_refactor_terms)\n",
        "\n",
        "def build_refactor_regex(use_conventional_commits=True):\n",
        "    header_regex =  '(?:^|^[\\s\\S]{0,25}%s)(?:%s)%s' % (term_seperator\n",
        "                                                       , \"|\".join(perfective_header_action)\n",
        "                                                       , term_seperator)\n",
        "\n",
        "    activity_regerx = \"(?:(?:%s)(?:%s|%s[\\s\\S]{0,50}%s)(?:%s)%s)\" % (build_sepereted_term(modification_activity\n",
        "                                                                                          , just_before=True)\n",
        "                                                                     , term_seperator\n",
        "                                                                     , term_seperator\n",
        "                                                                     , term_seperator\n",
        "                                                                     , \"|\".join(refactor_entities)\n",
        "                                                                     , term_seperator)\n",
        "    if use_conventional_commits:\n",
        "        agg_re = \"(%s)|(%s)|(%s)|(%s)\" % (build_sepereted_term(refactor_context)\n",
        "                          , activity_regerx\n",
        "                          , header_regex\n",
        "                          , build_cc_refactor_regex())\n",
        "    else:\n",
        "        agg_re = \"(%s)|(%s)|(%s)\" % (build_sepereted_term(refactor_context)\n",
        "                          , activity_regerx\n",
        "                          , header_regex)\n",
        "    return agg_re\n",
        "\n",
        "\n",
        "\n",
        "def build_refactor_goals_regex():\n",
        "    goals_regerx = \"(?:(?:%s)(?:%s|%s[\\s\\S]{0,50}%s)(?:%s)%s)\" % (build_sepereted_term(software_goals_modification\n",
        "                                                                                       , just_before=True)\n",
        "                                                                  , term_seperator\n",
        "                                                                  , term_seperator\n",
        "                                                                  , term_seperator\n",
        "                                                                  , \"|\".join(software_goals)\n",
        "                                                                  , term_seperator)\n",
        "    return goals_regerx\n",
        "\n",
        "\n",
        "def build_non_code_perfective_regex():\n",
        "\n",
        "    non_perfective_entities = ['warning(?:s)?'\n",
        "                               , 'format(?:ing)?'\n",
        "                               , 'indentation(?:s)?'\n",
        "                              ]\n",
        "    # TODO - applied to perfective entities too here, which is a bug.\n",
        "    modification_action = ['clean(?:-| )?up(?:s)?']\n",
        "    non_perfective_context = [\n",
        "                            'fix(?:es|ed|ing)?'\n",
        "                            ,'(?:get|got|getting) rid'\n",
        "                            , 'support(?:s|ed|ing)?'\n",
        "                            ]\n",
        "    modifiers = modification_activity + non_perfective_context\n",
        "    activity_regerx = \"((?:%s)(?:\\s|%s[\\s\\S]{0,50}%s)(?:%s))\" % (build_sepereted_term(modifiers, just_before=True)\n",
        "                                                                                , term_seperator\n",
        "                                                                                , term_seperator\n",
        "                                                                                , \"|\".join(prefective_entities\n",
        "                                                                                           + non_perfective_entities))\n",
        "    doc_header_regex =  '(?:^|^[\\s\\S]{0,25}%s)(?:%s)[\\s\\S]{0,25}(?:%s)' % (term_seperator\n",
        "                                                       , \"|\".join(perfective_header_action)\n",
        "                                                       , build_sepereted_term(documentation_entities))\n",
        "\n",
        "\n",
        "    no_prefective_action = \"|\".join([\n",
        "        'convert(?:ed|s|ing)?(?:%s|%s[\\s\\S]{0,50}%s)support(?:s|ed|ing)?' % (\n",
        "            term_seperator,term_seperator, term_seperator)\n",
        "        , '(?:make|made|making|makes)(?:%s|%s[\\s\\S]{0,50}%s)work' % (term_seperator, term_seperator, term_seperator)\n",
        "        , '(?:make|made|making|makes)(?:%s|%s[\\s\\S]{0,50}%s)sense' % (term_seperator, term_seperator, term_seperator)\n",
        "        , 'improv(?:e|es|ed|ing) handling'\n",
        "        , 'need(?:s|ing)?\\srefactor(?:ing)?'\n",
        "        , '(?:%s)(?:%s|%s[\\s\\S]{0,50}%s)(?:%s)' %(build_sepereted_term(non_perfective_entities,just_before=True)\n",
        "                                                   ,term_seperator\n",
        "                                                   , term_seperator\n",
        "                                                   , term_seperator\n",
        "                                                   , \"|\".join(modification_action)\n",
        "                                                   )\n",
        "        , doc_header_regex\n",
        "\n",
        "    ])\n",
        "    non_perfective_context = '(?:%s|%s)' % (no_prefective_action\n",
        "                                         , activity_regerx)\n",
        "\n",
        "    return non_perfective_context\n",
        "\n",
        "\n",
        "def build_documentation_entities_context(positive_re):\n",
        "\n",
        "    return '(?:%s)' % \"|\".join([\n",
        "        # TODO - take care of documentation entities spereatly\n",
        "         '(?:%s)[\\s\\S]{0,10}(?:%s)' % (build_sepereted_term(documentation_entities, just_before=True)\n",
        "                                        ,positive_re)\n",
        "    ])\n",
        "\n",
        "def build_perfective_regex():\n",
        "    non_code = build_sepereted_term (prefective_entities)\n",
        "\n",
        "    perfective = \"(%s)\" %  non_code\n",
        "\n",
        "    return perfective"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u49qh7rDTxWx"
      },
      "source": [
        "**Classification Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSkGaK72U5e4"
      },
      "source": [
        "def is_security(commit_text):\n",
        "\n",
        "    return (len(re.findall(build_positive_regex(), commit_text))\n",
        "            - len(re.findall(build_excluded_regex(), commit_text))\n",
        "            - len(re.findall(build_not_positive_regex(), commit_text)))  > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GHsYDR4T1vp"
      },
      "source": [
        "def is_core_bug(commit_text):\n",
        "    text = commit_text.lower()\n",
        "\n",
        "    cnt = len(re.findall(build_core_bug_regex(), text))\n",
        "\n",
        "    return cnt > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57w-T1gzT2aZ"
      },
      "source": [
        "def is_fix(commit_text):\n",
        "\n",
        "    text = commit_text.lower()\n",
        "    #text = normalize(text)\n",
        "\n",
        "    fix_num = len(re.findall(build_bug_fix_regex(), text))\n",
        "    valid_num = len(re.findall(build_valid_find_regex(), text))\n",
        "    negated_num = len(re.findall(build_negeted_bug_fix_regex(), text))\n",
        "    # TODO  consider modals\n",
        "    #negated_num = len(re.findall(build_non_positive_linguistic(build_bug_fix_regex()), text))\n",
        "    return (fix_num - valid_num - negated_num) > 0\n",
        "    #return (fix_num ) > 0 # max recall with current predictor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnMRkz94V_oX"
      },
      "source": [
        "def is_adaptive(text):\n",
        "\n",
        "    x = (match(text, build_adaptive_regex())\n",
        "            + match(text, build_adaptive_action_regex())\n",
        "            - match(text, build_non_adaptive_context())\n",
        "            - match(text, build_non_adaptive_linguistic()))\n",
        "    \n",
        "    if x > 0:\n",
        "      return True\n",
        "    else:\n",
        "      return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGRvATZtWVd5"
      },
      "source": [
        "def built_is_refactor(commit_text):\n",
        "    removal_re = build_sepereted_term(removal)\n",
        "\n",
        "    return (match(commit_text, build_refactor_regex())\n",
        "            + match(commit_text, removal_re)\n",
        "            + match(commit_text, build_refactor_goals_regex())\n",
        "            - match(commit_text, build_non_code_perfective_regex())\n",
        "            - match(commit_text\n",
        "                    , build_documentation_entities_context(build_refactor_regex(use_conventional_commits=False)))\n",
        "            - match(commit_text\n",
        "                    , build_non_positive_linguistic(build_refactor_regex(use_conventional_commits=False)))\n",
        "            - match(commit_text, build_non_positive_linguistic(build_sepereted_term(removal)))\n",
        "            - match(commit_text, build_non_positive_linguistic(build_refactor_goals_regex()))\n",
        "            ) > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Dzf28wsGppN"
      },
      "source": [
        "This function returns a category based on the commit message. It is important to note the sequential manner that the messages are regex matched. Therefore, this order of funciton checking ensures that the latter functions has a broader vocabulary of keywords. This is a limitation of adding this category feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA90RBMVq89o"
      },
      "source": [
        "def categorize_message_single(sample):\n",
        "\n",
        "  if len(str(sample['message']).strip()) == 0:\n",
        "    return 'other'\n",
        "\n",
        "  if is_security(str(sample['message'])):\n",
        "    return 'security'\n",
        "\n",
        "  if is_fix(str(sample['message'])):\n",
        "    return 'fix'\n",
        "\n",
        "  if built_is_refactor(str(sample['message'])):\n",
        "    return 'refactor'\n",
        "\n",
        "  if is_core_bug(str(sample['message'])):\n",
        "    return 'bug'\n",
        "\n",
        "  if is_adaptive(str(sample['message'])):\n",
        "    return 'other'\n",
        "\n",
        "  return 'other'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv06UMfj_buj"
      },
      "source": [
        "These function adds the one hot labels, based on the previously identified categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7DAFSZoe9Cz"
      },
      "source": [
        "def cat_bug(cat):\n",
        "  if str(cat['category']) == \"bug\":\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def cat_other(cat):\n",
        "  if str(cat['category']) == \"other\":\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def cat_security(cat):\n",
        "  if str(cat['category']) == \"security\":\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def cat_fix(cat):\n",
        "  if str(cat['category']) == \"fix\":\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def cat_refactor(cat):\n",
        "  if str(cat['category']) == \"refactor\":\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fmb70YRpJVO"
      },
      "source": [
        "df['category'] = df.apply(categorize_message_single, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "wGD6tKYHILsB",
        "outputId": "042e69c2-8057-4c83-ec22-42e4c73ea202"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commit</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>message</th>\n",
              "      <th>repo</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1805462</th>\n",
              "      <td>bc4225320c87ac1d8e4bfd84719b227abf78c109</td>\n",
              "      <td>Mark Johnston &lt;markj@FreeBSD.org&gt;</td>\n",
              "      <td>Tue Oct 8 23:52:04 2019 +0000</td>\n",
              "      <td>Fix a bug in r353332 that snuck in with a last...</td>\n",
              "      <td>freebsd/freebsd-src</td>\n",
              "      <td>fix</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415020</th>\n",
              "      <td>2e0d6d49bf6c95185229ac19f8b1c43f1bca31fd</td>\n",
              "      <td>bjorn3 &lt;bjorn3@users.noreply.github.com&gt;</td>\n",
              "      <td>Sat Aug 11 13:59:08 2018 +0200</td>\n",
              "      <td>Deduplicate function name generation</td>\n",
              "      <td>rust-lang/rust</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1977842</th>\n",
              "      <td>a30d7c60f602d4c7c983e3f91aea34518e094567</td>\n",
              "      <td>Jake Burkholder &lt;jake@FreeBSD.org&gt;</td>\n",
              "      <td>Sat Apr 6 08:13:52 2002 +0000</td>\n",
              "      <td>Use CTASSERT rather than a runtime check to de...</td>\n",
              "      <td>freebsd/freebsd-src</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3861214</th>\n",
              "      <td>0c998f41594caadfb00d22e512c3e06f247e24de</td>\n",
              "      <td>abarth@chromium.org &lt;abarth@chromium.org@bbb92...</td>\n",
              "      <td>Thu May 30 18:32:28 2013 +0000</td>\n",
              "      <td>Add Adam Klein as a Core OWNER\\n    \\n    He w...</td>\n",
              "      <td>chromium/chromium</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2840851</th>\n",
              "      <td>e0a70217107e6f9844628120412cb27bb4cea194</td>\n",
              "      <td>Oleg Nesterov &lt;oleg@redhat.com&gt;</td>\n",
              "      <td>Fri Nov 5 16:53:42 2010 +0100</td>\n",
              "      <td>posix-cpu-timers: workaround to suppress the p...</td>\n",
              "      <td>torvalds/linux</td>\n",
              "      <td>fix</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3747827</th>\n",
              "      <td>76b735208764148d18bac5e1c91ec20cd464c01b</td>\n",
              "      <td>garykac &lt;garykac@chromium.org&gt;</td>\n",
              "      <td>Tue Nov 18 09:28:10 2014 -0800</td>\n",
              "      <td>[Chromoting] Add auth dialog to window shape\\n...</td>\n",
              "      <td>chromium/chromium</td>\n",
              "      <td>security</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3885810</th>\n",
              "      <td>ebe123f9aeb87467c0cdf8145d8194811f1decc0</td>\n",
              "      <td>nfullagar@chromium.org &lt;nfullagar@chromium.org...</td>\n",
              "      <td>Wed Feb 13 01:10:22 2013 +0000</td>\n",
              "      <td>Hush compiler warnings when compiling c code.\\...</td>\n",
              "      <td>chromium/chromium</td>\n",
              "      <td>fix</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1847141</th>\n",
              "      <td>4a0589d1ba7b8738639f5d9f6ef585531c1990f4</td>\n",
              "      <td>Konstantin Belousov &lt;kib@FreeBSD.org&gt;</td>\n",
              "      <td>Thu Aug 20 13:37:08 2015 +0000</td>\n",
              "      <td>Typo.</td>\n",
              "      <td>freebsd/freebsd-src</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3021469</th>\n",
              "      <td>bed8bdfddd851657cf9e5fd16bb44abb02ae7f42</td>\n",
              "      <td>Eric Sesterhenn &lt;snakebyte@gmx.de&gt;</td>\n",
              "      <td>Mon Oct 23 22:17:21 2006 +0200</td>\n",
              "      <td>IB: kmemdup() cleanup\\n    \\n    Replace open ...</td>\n",
              "      <td>torvalds/linux</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3477480</th>\n",
              "      <td>df16d7801416be35e6cd8f0dd473ad981baa3fc7</td>\n",
              "      <td>Charlie Harrison &lt;csharrison@chromium.org&gt;</td>\n",
              "      <td>Tue May 15 22:42:17 2018 +0000</td>\n",
              "      <td>Remove SubresourceFilter.SafeBrowsing.CheckDis...</td>\n",
              "      <td>chromium/chromium</td>\n",
              "      <td>fix</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           commit  ...  category\n",
              "1805462  bc4225320c87ac1d8e4bfd84719b227abf78c109  ...       fix\n",
              "415020   2e0d6d49bf6c95185229ac19f8b1c43f1bca31fd  ...     other\n",
              "1977842  a30d7c60f602d4c7c983e3f91aea34518e094567  ...     other\n",
              "3861214  0c998f41594caadfb00d22e512c3e06f247e24de  ...     other\n",
              "2840851  e0a70217107e6f9844628120412cb27bb4cea194  ...       fix\n",
              "3747827  76b735208764148d18bac5e1c91ec20cd464c01b  ...  security\n",
              "3885810  ebe123f9aeb87467c0cdf8145d8194811f1decc0  ...       fix\n",
              "1847141  4a0589d1ba7b8738639f5d9f6ef585531c1990f4  ...     other\n",
              "3021469  bed8bdfddd851657cf9e5fd16bb44abb02ae7f42  ...     other\n",
              "3477480  df16d7801416be35e6cd8f0dd473ad981baa3fc7  ...       fix\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7n5uvf2d9d1"
      },
      "source": [
        "df.to_csv(f'/content/github_categories.csv', index = False, encoding = 'utf-8') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eW4dy1edzLO",
        "outputId": "84445be5-1f99-4d1a-9ac1-af58f9029724"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z6F7g-oZd11r",
        "outputId": "88751a9e-7dd8-4088-affd-0889e1685c9a"
      },
      "source": [
        "# import shutil\n",
        "# shutil.copy(\"/content/github_categories.csv\", \"/content/gdrive/MyDrive/\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/github_categories.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBq68-AyEp3l"
      },
      "source": [
        "Adding One Hot Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX2xDRSdqWhR"
      },
      "source": [
        "newdf = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3EFv2oKqYFQ"
      },
      "source": [
        "newdf['other'] = newdf.apply(cat_other, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZw62CkRroiY"
      },
      "source": [
        "newdf['bug'] = newdf.apply(cat_bug, axis=1)\n",
        "newdf['fix'] = newdf.apply(cat_fix, axis=1)\n",
        "newdf['refactor'] = newdf.apply(cat_refactor, axis=1)\n",
        "newdf['security'] = newdf.apply(cat_security, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "TEwplNtkskXy",
        "outputId": "9f96dd38-3995-4cfc-85b7-f6a8039021b2"
      },
      "source": [
        "newdf.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>message</th>\n",
              "      <th>other</th>\n",
              "      <th>bug</th>\n",
              "      <th>fix</th>\n",
              "      <th>refactor</th>\n",
              "      <th>security</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3804104</th>\n",
              "      <td>384b92661c8bfa0c80b92cfa4d1118cd9de0dc6d</td>\n",
              "      <td>Revert 254791 \"Disable HostDriven_SyncTest.tes...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4073714</th>\n",
              "      <td>e360fac83f6c27336fc2411ac19ba4a75f4b0683</td>\n",
              "      <td>Since the host content settings preferences ca...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2386411</th>\n",
              "      <td>c499a64f349d063d8cdb40c0b96e84c35bbc414c</td>\n",
              "      <td>net: dsa: mv88e6xxx: move VTU Data accessors\\n...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2582938</th>\n",
              "      <td>f74954f01ec9bb2004bcc24f247d1f26f1063ad2</td>\n",
              "      <td>x86: Unwind-annotate thunk_32.S\\n    \\n    Sig...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995118</th>\n",
              "      <td>74b7d742acf4dbde32d4486d747be82ea9cda039</td>\n",
              "      <td>Update .DEPS.git\\n    \\n    git-svn-id: svn://...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2784135</th>\n",
              "      <td>a7e3bd669eb407b4e700a023e502bfc80d814b04</td>\n",
              "      <td>staging:iio:light:tsl2563 both intensity chann...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3728489</th>\n",
              "      <td>47904be75e5fdea64ba0b4c49472b722aabf6a43</td>\n",
              "      <td>Roll src/third_party/skia b421650:7ab4277\\n   ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2239326</th>\n",
              "      <td>18c0778a650b21f8729576b7bc382447d2027d4d</td>\n",
              "      <td>NFSv4: Handle early exit in layoutget by retur...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2967420</th>\n",
              "      <td>94ee1cf5a88e12f5cbf8c0c78a6c18d3e043241e</td>\n",
              "      <td>edac: add e752x parameter for sysbus_parity se...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850557</th>\n",
              "      <td>17d52d23512fd5913fe6628609a57744dfdb6ba3</td>\n",
              "      <td>Improve smb(4) man page.\\n    \\n    Differenti...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               id  ... security\n",
              "3804104  384b92661c8bfa0c80b92cfa4d1118cd9de0dc6d  ...        0\n",
              "4073714  e360fac83f6c27336fc2411ac19ba4a75f4b0683  ...        0\n",
              "2386411  c499a64f349d063d8cdb40c0b96e84c35bbc414c  ...        0\n",
              "2582938  f74954f01ec9bb2004bcc24f247d1f26f1063ad2  ...        0\n",
              "3995118  74b7d742acf4dbde32d4486d747be82ea9cda039  ...        0\n",
              "2784135  a7e3bd669eb407b4e700a023e502bfc80d814b04  ...        0\n",
              "3728489  47904be75e5fdea64ba0b4c49472b722aabf6a43  ...        0\n",
              "2239326  18c0778a650b21f8729576b7bc382447d2027d4d  ...        0\n",
              "2967420  94ee1cf5a88e12f5cbf8c0c78a6c18d3e043241e  ...        0\n",
              "1850557  17d52d23512fd5913fe6628609a57744dfdb6ba3  ...        0\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gLmkAEzsjvp"
      },
      "source": [
        "newdf = newdf.drop(['author', 'date', 'repo', 'category'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4Z2-K_gtDAz"
      },
      "source": [
        "newdf.rename(columns = {'commit':'id'}, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lMCxNo8tTBJ"
      },
      "source": [
        "newdf.to_csv(f'/content/github_training.csv', index = False, encoding = 'utf-8') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2_Qqm3iCtbmg",
        "outputId": "b4b73d7a-90ff-4ffa-ef03-67c84297e312"
      },
      "source": [
        "# shutil.copy(\"/content/github_training.csv\", \"/content/gdrive/MyDrive/\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/github_training.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    }
  ]
}